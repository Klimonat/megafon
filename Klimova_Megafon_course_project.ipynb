{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import datetime as dtm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data_train.csv')\n",
    "data_test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = 'D:/Geekbrains/Мегафон/features.csv/'\n",
    "df_features = dd.read_csv(path + 'features.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуальный просмотр данных и их размерностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['buy_time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['buy_time'].drop_duplicates().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_features.shape[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слияние данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_in_train = list(data_train.id)\n",
    "id_in_test = list(data_test.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(id_in_train))\n",
    "print(len(id_in_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_features_for_train = df_features[df_features.id.isin(id_in_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_features_for_train_in_pd = df_features_for_train.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_for_train_in_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_features_for_test = df_features[df_features.id.isin(id_in_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_features_for_test_in_pd = df_features_for_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_for_test_in_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data_train = data_train.sort_values(by='id')\n",
    "sort_df_features_for_train_in_pd = df_features_for_train_in_pd.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data_test = data_test.sort_values(by='id')\n",
    "sort_df_features_for_test_in_pd = df_features_for_test_in_pd.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_train = pd.merge_asof(sort_data_train, sort_df_features_for_train_in_pd, on='id', by='buy_time', direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_test = pd.merge_asof(sort_data_test, sort_df_features_for_test_in_pd, on='id', by='buy_time', direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# full_train.reset_index(drop=True).to_csv('full_train.csv')\n",
    "# full_test.reset_index(drop=True).to_csv('full_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_features\n",
    "del data_train\n",
    "del df_features_for_train\n",
    "del df_features_for_test\n",
    "del df_features_for_train_in_pd\n",
    "del df_features_for_test_in_pd\n",
    "del sort_data_train\n",
    "del sort_df_features_for_train_in_pd\n",
    "del sort_data_test\n",
    "del sort_df_features_for_test_in_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# full_train = pd.read_csv('full_train.csv')\n",
    "# full_test = pd.read_csv('full_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Столбцы 'Unnamed: 0_x' и 'Unnamed: 0_y' удалим, т.к. они не являются признаками, а отображают только порядок, индексы\n",
    "full_train.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'], inplace=True)\n",
    "full_test.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_columns_in_train = list(full_train.columns)\n",
    "name_columns_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_len = full_train.shape[0]\n",
    "for column_name in name_columns_in_train:\n",
    "    if full_train[column_name].count() != full_len:\n",
    "        count_nan = full_len - full_train[column_name].count()\n",
    "        print('В столбце {column_name} пропущено {count_nan} значений')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тренировочном датасете нет пропущенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается сильный дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_train = full_train.sort_values(by='buy_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dtm.datetime.fromtimestamp(min(sort_train.buy_time)))\n",
    "print(dtm.datetime.fromtimestamp(max(sort_train.buy_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(sort_train.buy_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(dtm.datetime.strptime('01.12.2018 00:00:00', '%d.%m.%Y %H:%M:%S').timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_separation = int(dtm.datetime.strptime('01.12.2018 00:00:00', '%d.%m.%Y %H:%M:%S').timestamp())\n",
    "df_train = sort_train[sort_train.buy_time < timestamp_separation]\n",
    "df_test = sort_train[sort_train.buy_time >= timestamp_separation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['target'])\n",
    "y_train = df_train.target\n",
    "X_test = df_test.drop(columns=['target'])\n",
    "y_test_real = df_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name_features = list(X_train.columns)[3:]\n",
    "list_name_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция создания, обучения модели, формирования предсказаний и подсчета метрик\n",
    "def model_preds(model, X_train, y_train, X_test, y_test_real):\n",
    "    model_class = RandomForestClassifier(random_state=21, class_weight={0 : 1, 1 : 10})\n",
    "    model_class.fit(X_train, y_train)\n",
    "    y_preds = model_class.predict(X_test)\n",
    "    metrics = f1_score(y_test_real, y_preds, average='macro')\n",
    "    return model_class, y_preds, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датафрейм с результатами\n",
    "columns_name = ['model', 'standart', 'with_std', 'with_PCA_and_std', \n",
    "                'for_slice', 'for_slice_with_std', 'for_slice_with_std_and_PCA']\n",
    "df_metrics_for_models = pd.DataFrame(columns=columns_name)\n",
    "df_metrics_for_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим модель Random Forest без дополнительных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rf = RandomForestClassifier(random_state=21)\n",
    "trained_model_rf, y_preds_rf, metrics_rf = model_preds(model_rf, X_train, y_train, X_test, y_test_real)\n",
    "metrics_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели Random Forest с весами для классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rf_with_std = RandomForestClassifier(random_state=21, class_weight={0 : 1, 1 : 10})\n",
    "trained_model_rf_with_std, y_preds_rf_with_std, metrics_rf_with_std = model_preds(model_rf_with_std, X_train, y_train, \\\n",
    "                                                                                  X_test, y_test_real)\n",
    "metrics_rf_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "X_std_train = X_train.copy()\n",
    "X_std_train[list_name_features] = standard_scaler.fit_transform(X_std_train[list_name_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std_test = X_test.copy()\n",
    "X_std_test[list_name_features] = standard_scaler.fit_transform(X_std_test[list_name_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rf_with_weight = RandomForestClassifier(random_state=21, class_weight={0.0 : 1, 1.0 : 10})\n",
    "model_rf_with_weight.fit(X_std_train, y_train)\n",
    "y_preds_rf_with_weight = model_rf_with_weight.predict(X_std_test)\n",
    "f1_score(y_test_real, y_preds_rf_with_weight, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### При помощи модели Random Forest выявим наиболее важные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame({'feature': X_std_train.columns, \n",
    "                                      'importance': model_rf_with_weight.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.sort_values(by='importance', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std_train[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель random forest для части признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rf_for_slice = RandomForestClassifier(random_state=21)\n",
    "trained_model_rf_for_slice, y_preds_rf_for_slice, metrics_rf_for_slice = model_preds(model_rf_for_slice, \n",
    "                     X_std_train[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)], \n",
    "                     y_train, X_test[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)],\n",
    "                     y_test_real)\n",
    "metrics_rf_for_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель random forest для части признаков с переопределением весов целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rf_for_slice_with_std = RandomForestClassifier(random_state=21, class_weight={0 : 1, 1 : 10})\n",
    "trained_model_rf_for_slice_with_std, y_preds_rf_for_slice_with_std, metrics_rf_for_slice_with_std = model_preds(model_rf_for_slice_with_std, \n",
    "                     X_std_train[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)], \n",
    "                     y_train, X_test[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)], \n",
    "                     y_test_real)\n",
    "metrics_rf_for_slice_with_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обучения pipeline, формирования предсказаний и подсчета метрик\n",
    "def pipeline_preds(pipeline, X_train, y_train, X_test, y_test_real):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_preds = pipeline.predict(X_test)\n",
    "    metrics = f1_score(y_test_real, y_preds, average='macro')\n",
    "    return pipeline, y_preds, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим pipeline для модели random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_rf_with_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "#                         ('random_forest', RandomForestClassifier(random_state=21))])\n",
    "# trained_model_rf_with_std, y_preds_rf_with_std, metrics_rf_with_std = pipeline_preds(pipeline_rf_with_std, \n",
    "#                                          X_train, y_train, X_test, y_test_real)\n",
    "# metrics_rf_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим PCA в pipeline для random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_rf_with_pca = Pipeline([('pca', PCA()),\n",
    "#                         ('standard_scaler', StandardScaler()), \n",
    "#                         ('random_forest', RandomForestClassifier(random_state=21))])\n",
    "# trained_model_rf_with_std_and_PCA, y_preds_rf_with_std_and_PCA, metrics_rf_with_std_and_PCA = pipeline_preds(pipeline_rf_with_pca, X_train, y_train, X_test, y_test_real)\n",
    "# metrics_rf_with_std_and_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим PCA в pipeline для random forest для части признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_slice = X_train[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)]\n",
    "X_test_slice = X_test[list(df_feature_importance[df_feature_importance.importance > 0.002].feature.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_rf_slice_with_pca = Pipeline([('pca', PCA()),\n",
    "#                         ('standard_scaler', StandardScaler()), \n",
    "#                         ('random_forest', RandomForestClassifier(random_state=21))])\n",
    "# trained_model_rf_slice_with_std_and_PCA, y_preds_rf_slice_with_std_and_PCA, metrics_rf_slice_with_std_and_PCA = pipeline_preds(pipeline_rf_slice_with_pca, \n",
    "#                         X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "# metrics_rf_slice_with_std_and_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим результаты вычисления метрик в общий датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rf_with_std_and_PCA = np.nan\n",
    "metrics_rf_slice_with_std_and_PCA = np.nan\n",
    "result_for_rf = ['Random Forest', metrics_rf, metrics_rf_with_std, metrics_rf_with_std_and_PCA, \n",
    "                metrics_rf_for_slice, metrics_rf_for_slice_with_std, metrics_rf_slice_with_std_and_PCA]\n",
    "df_result_for_rf = pd.DataFrame([result_for_rf], columns=columns_name)\n",
    "df_metrics_for_models = pd.concat([df_metrics_for_models, df_result_for_rf], axis=0, ignore_index=True)\n",
    "df_metrics_for_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим алгоритм logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_lr = Pipeline([('logistic_regression', LogisticRegression(random_state=21))])\n",
    "trained_model_lr, y_preds_lr, metrics_lr = pipeline_preds(pipeline_lr, X_train, y_train, X_test, y_test_real)\n",
    "metrics_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в logistic regression стандартизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_lr_with_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "                        ('logistic_regression', LogisticRegression(random_state=21))])\n",
    "trained_model_lr_with_std, y_preds_lr_with_std, metrics_lr_with_std = pipeline_preds(pipeline_lr_with_std, \n",
    "                        X_train, y_train, X_test, y_test_real)\n",
    "metrics_lr_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в logistic regression стандартизацию и PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_lr_with_std_pca = Pipeline([('pca', PCA()),\n",
    "                                   ('standard_scaler', StandardScaler()), \n",
    "                                    ('logistic_regression', LogisticRegression(random_state=21))])\n",
    "trained_model_lr_with_std_pca, y_preds_lr_with_std_pca, metrics_lr_with_std_pca = pipeline_preds(pipeline_lr_with_std_pca, \n",
    "                                    X_train, y_train, X_test, y_test_real)\n",
    "metrics_lr_with_std_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим logistic regression для ограниченного набора признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_lr_slice = Pipeline([('logistic_regression', LogisticRegression(random_state=21))])\n",
    "trained_model_lr_slice, y_preds_lr_slice, metrics_lr_slice = pipeline_preds(pipeline_lr_slice, \n",
    "                                                X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "metrics_lr_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в logistic regression для ограниченного набора признаков стандартизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_lr_slice_with_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "                        ('logistic_regression', LogisticRegression(random_state=21))])\n",
    "trained_model_lr_slice_with_std, y_preds_lr_slice_with_std, metrics_lr_slice_with_std = pipeline_preds(pipeline_lr_slice_with_std, \n",
    "                        X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "metrics_lr_slice_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в logistic regression для ограниченного набора признаков стандартизацию и PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_lr_slice_with_std_pca = Pipeline([('pca', PCA()),\n",
    "                                   ('standard_scaler', StandardScaler()), \n",
    "                                    ('logistic_regression', LogisticRegression(random_state=21))])\n",
    "trained_model_lr_slice_with_std_pca, y_preds_lr_slice_with_std_pca, metrics_lr_slice_with_std_pca = pipeline_preds(pipeline_lr_slice_with_std_pca, \n",
    "                                    X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "metrics_lr_slice_with_std_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_for_logreg = ['Logistic Regression', metrics_lr, metrics_lr_with_std, metrics_lr_with_std_pca, \n",
    "                metrics_lr_slice, metrics_lr_slice_with_std, metrics_lr_slice_with_std_pca]\n",
    "df_result_for_logreg = pd.DataFrame([result_for_logreg], columns=columns_name)\n",
    "df_metrics_for_models = pd.concat([df_metrics_for_models, df_result_for_logreg], axis=0, ignore_index=True)\n",
    "df_metrics_for_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим модель Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_gb = Pipeline([('gradient_boosting', GradientBoostingClassifier(random_state=21))])\n",
    "trained_model_gb, y_preds_gb, metrics_gb = pipeline_preds(pipeline_gb, X_train, y_train, X_test, y_test_real)\n",
    "metrics_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим стандартизацию данных в модель Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_gb_with_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "                                ('gradient_boosting', GradientBoostingClassifier(random_state=21))])\n",
    "trained_model_gb_with_std, y_preds_gb_with_std, metrics_gb_with_std = pipeline_preds(pipeline_gb_with_std, \n",
    "                                    X_train, y_train, X_test, y_test_real)\n",
    "metrics_gb_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим стандартизацию данных и PCA в модель Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_gb_with_std_pca = Pipeline([('pca', PCA()),\n",
    "#                                 ('standard_scaler', StandardScaler()), \n",
    "#                                 ('gradient_boosting', GradientBoostingClassifier(random_state=21))])\n",
    "# trained_model_gb_with_std_pca, y_preds_gb_with_std_pca, metrics_gb_with_std_pca = pipeline_preds(pipeline_gb_with_std_pca, \n",
    "#                                     X_train, y_train, X_test, y_test_real)\n",
    "# metrics_gb_with_std_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель Gradient Boosting для отобранной части признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_gb_slice = Pipeline([('gradient_boosting', GradientBoostingClassifier(random_state=21))])\n",
    "trained_model_gb_slice, y_preds_gb_slice, metrics_gb_slice = pipeline_preds(pipeline_gb_slice, X_train_slice, \n",
    "                                                                            y_train, X_test_slice, y_test_real)\n",
    "metrics_gb_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель Gradient Boosting со стандартизацией данных для отобранной части признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_gb_slice_with_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "                                ('gradient_boosting', GradientBoostingClassifier(random_state=21))])\n",
    "trained_model_gb_slice_with_std, y_preds_gb_slice_with_std, metrics_gb_slice_with_std = pipeline_preds(pipeline_gb_slice_with_std, \n",
    "                                    X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "metrics_gb_slice_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель Gradient Boosting со стандартизацией данных и PCA для отобранной части признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_gb_with_slice_std_pca = Pipeline([('pca', PCA()),\n",
    "#                                 ('standard_scaler', StandardScaler()), \n",
    "#                                 ('gradient_boosting', GradientBoostingClassifier(random_state=21))])\n",
    "# trained_model_gb_slice_with_std_pca, y_preds_gb_slice_with_std_pca, metrics_gb_slice_with_std_pca = pipeline_preds(pipeline_gb_slice_with_std_pca, \n",
    "#                                     X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "# metrics_gb_slice_with_std_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_gb_with_std_pca = np.nan\n",
    "metrics_gb_slice_with_std_pca = np.nan\n",
    "result_for_gb = ['Gradient Boosting', metrics_gb, metrics_gb_with_std, metrics_gb_with_std_pca, \n",
    "                metrics_gb_slice, metrics_gb_slice_with_std, metrics_gb_slice_with_std_pca]\n",
    "df_result_for_gb = pd.DataFrame([result_for_gb], columns=columns_name)\n",
    "df_metrics_for_models = pd.concat([df_metrics_for_models, df_result_for_gb], axis=0, ignore_index=True)\n",
    "df_metrics_for_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим алгоритм knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_knn = Pipeline([('knn', KNeighborsClassifier())])\n",
    "trained_model_knn, y_preds_knn, metrics_knn = pipeline_preds(pipeline_knn, X_train, y_train, X_test, y_test_real)\n",
    "metrics_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим к алгоритму knn стандартизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_knn_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "                                ('knn', KNeighborsClassifier())])\n",
    "trained_model_knn_std, y_preds_knn_with_std, metrics_knn_with_std = pipeline_preds(pipeline_knn_std, X_train, y_train,\n",
    "                                                                                   X_test, y_test_real)\n",
    "metrics_knn_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим к алгоритму knn стандартизацию и PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_knn_std_pca = Pipeline([('pca', PCA()),\n",
    "#                                 ('standard_scaler', StandardScaler()), \n",
    "#                                 ('knn', KNeighborsClassifier())])\n",
    "# trained_model_knn_with_std_pca, y_preds_knn_with_std_pca, metrics_knn_with_std_pca = pipeline_preds(pipeline_knn_with_std_pca, \n",
    "#                                     X_train, y_train, X_test, y_test_real)\n",
    "# metrics_knn_with_std_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим алгоритм knn к ограниченному набору признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline_knn_with_slice = Pipeline([('knn', KNeighborsClassifier())])\n",
    "trained_model_knn_slice, y_preds_knn_slice, metrics_knn_slice = pipeline_preds(pipeline_knn_with_slice, \n",
    "                                    X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "metrics_knn_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим к алгоритму knn для ограниченного набора признаков стандартизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_knn_with_slice_std = Pipeline([('standard_scaler', StandardScaler()), \n",
    "#                                 ('knn', KNeighborsClassifier())])\n",
    "# trained_model_knn_slice_with_std, y_preds_knn_slice_with_std, metrics_knn_slice_with_std = pipeline_preds(pipeline_knn_with_slice_std, \n",
    "#                                     X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "# metrics_knn_slice_with_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель knn со стандартизацией данных и PCA для отобранной части признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline_knn_with_slice_std_pca = Pipeline([('pca', PCA()),\n",
    "#                                 ('standard_scaler', StandardScaler()), \n",
    "#                                 ('knn', KNeighborsClassifier())])\n",
    "# trained_model_knn_slice_with_std_pca, y_preds_knn_slice_with_std_pca, metrics_knn_slice_with_std_pca = pipeline_preds(pipeline_knn_with_slice_std_pca, \n",
    "#                                     X_train_slice, y_train, X_test_slice, y_test_real)\n",
    "# metrics_knn_slice_with_std_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_knn_with_std_pca = np.nan\n",
    "metrics_knn_slice_with_std = np.nan\n",
    "metrics_knn_slice_with_std_pca = np.nan\n",
    "result_for_knn = ['K Neighbors Classifier', metrics_knn, metrics_knn_with_std, metrics_knn_with_std_pca, \n",
    "                metrics_knn_slice, metrics_knn_slice_with_std, metrics_knn_slice_with_std_pca]\n",
    "df_result_for_knn = pd.DataFrame([result_for_knn], columns=columns_name)\n",
    "df_metrics_for_models = pd.concat([df_metrics_for_models, df_result_for_knn], axis=0, ignore_index=True)\n",
    "df_metrics_for_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат дала модель GradientBoostingClassifier без стандартизации. Подберем гиперпараметры для этой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {'n_estimators': [100, 200, 300], 'max_depth': [1, 3, 5, 10]}\n",
    "model_gb = GradientBoostingClassifier(random_state=21)\n",
    "f1 = make_scorer(f1_score, average='macro')\n",
    "grid_search_for_gb = GridSearchCV(model_gb, parameters, scoring=f1)\n",
    "grid_search_for_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_for_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_for_gb.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Финальное обучение модели, соранение модели и выполнение предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = full_train.drop(columns=['target'])\n",
    "y_train_final = full_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = GradientBoostingClassifier(random_state=21, max_depth=3, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_final = best_model.predict(full_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_result['target'] = y_predict_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = full_test_result[['id', 'vas_id', 'buy_time', 'target']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('answers_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_model.pkl', 'rb') as file: \n",
    "    pickle_model = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_model.predict(full_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
